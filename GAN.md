## GAN用了零和博弈

GAN的目的：通过输入一个“噪声”/正态/高斯分布，得到可以以假乱真的“假样本”或是分布。

博弈双方是：生成模型（G）和判别模型（D）。两者都可以看做是黑匣子，接受输入然后有一个输出，类似一个函数，有输入输出映射。

生成模型的功能是生成样本；目的是为了让判别模型无法判断到底是真样本还是生成的假样本。
判别模型的功能是二分类器（如同0-1分类器），来判断输入的样本是真真假。
这也就是“对抗网络”的意思：判别网络说，我很强，我要分辨你。生成网络表示不服，说我穿了马甲，你无法辨别——>纳什均衡。
两者相互独立，也不好一起训练，因此 ## 单独交替迭代训练 ##。


假设现在生成网络模型已经有了（当然可能不是最好的生成网络），那么给一堆随机数组，就会得到一堆假的样本集（因为不是最终的生成模型，那么现在生成网络可能就处于劣势，导致生成的样本就不咋地，可能很容易就被判别网络判别出来了说这货是假冒的），但是先不管这个，假设我们现在有了这样的假样本集，真样本集一直都有，现在我们人为的定义真假样本集的标签，因为我们希望真样本集的输出尽可能为1，假样本集为0，很明显这里我们就已经默认真样本集所有的类标签都为1，而假样本集的所有类标签都为0. 



有人会说，在真样本集里面的人脸中，可能张三人脸和李四人脸不一样呀，对于这个问题我们需要理解的是，我们现在的任务是什么，我们是想分样本真假，而不是分真样本中那个是张三label、那个是李四label。况且我们也知道，原始真样本的label我们是不知道的。回过头来，我们现在有了真样本集以及它们的label（都是1）、假样本集以及它们的label（都是0），这样单就判别网络来说，此时问题就变成了一个再简单不过的有监督的二分类问题了，直接送到神经网络模型中训练就完事了。假设训练完了，下面我们来看生成网络。



对于生成网络，想想我们的目的，是生成尽可能逼真的样本。那么原始的生成网络生成的样本你怎么知道它真不真呢？就是送到判别网络中，所以在训练生成网络的时候，我们需要联合判别网络一起才能达到训练的目的。什么意思？就是如果我们单单只用生成网络，那么想想我们怎么去训练？误差来源在哪里？细想一下没有，但是如果我们把刚才的判别网络串接在生成网络的后面，这样我们就知道真假了，也就有了误差了。所以对于生成网络的训练其实是对生成-判别网络串接的训练，就像图中显示的那样。好了那么现在来分析一下样本，原始的噪声数组Z我们有，也就是生成了假样本我们有，此时很关键的一点来了，我们要把这些假样本的标签都设置为1，也就是认为这些假样本在生成网络训练的时候是真样本。
